{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data:\n",
      "Deutsch:  Ohne Zweifel findet sich auf dieser Welt zu jedem Mann genau die richtige Ehefrau und umgekehrt; wenn man jedoch in Betracht zieht, dass ein Mensch nur Gelegenheit hat, mit ein paar hundert anderen bekannt zu sein, von denen ihm nur ein Dutzend oder weniger nahesteht, darunter höchstens ein oder zwei Freunde, dann erahnt man eingedenk der Millionen Einwohner dieser Welt leicht, dass seit Erschaffung ebenderselben wohl noch nie der richtige Mann der richtigen Frau begegnet ist.\n",
      "English:  Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# Data from http://www.manythings.org/anki/.\n",
    "path_to_file = pathlib.Path(\"/tf/code/piplinjen/notebooks/deu-eng/deu.txt\")\n",
    "\n",
    "def load_data(path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "    inp = [inp for targ, inp, _ in pairs]\n",
    "    targ = [targ for targ, inp, _ in pairs]\n",
    "\n",
    "    return targ, inp\n",
    "\n",
    "targ, inp = load_data(path_to_file)\n",
    "\n",
    "print(\"Example data:\")\n",
    "print(\"Deutsch: \", inp[-1])\n",
    "print(\"English: \", targ[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tf.Tensor(\n",
      "[b'Ihr h\\xc3\\xa4ttet weglaufen k\\xc3\\xb6nnen.' b'Ich reise oft.'\n",
      " b'Wir sind hier, um ihnen zu helfen.'\n",
      " b'Tom ist ein h\\xc3\\xb6flicher Junge.' b'Sie schaute zur Decke hoch.'], shape=(5,), dtype=string)\n",
      "Target:  tf.Tensor(\n",
      "[b\"You could've run away.\" b'I often travel.' b\"We're here to help them.\"\n",
      " b'Tom is a kind boy.' b'She looked up at the ceiling.'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensorflow dataset.\n",
    "BUFFER_SIZE = len(inp)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "\n",
    "for inp_batch, targ_batch in dataset.take(1):\n",
    "    print(\"Input: \", inp_batch[:5])\n",
    "    print(\"Target: \", targ_batch[:5])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Verkr\\xc3\\xbcmele dich! Mach \\xe2\\x80\\x99ne Fliege! Mir ist hei\\xc3\\x9f.'\n",
      "b'Verkru\\xcc\\x88mele dich! Mach \\xe2\\x80\\x99ne Fliege! Mir ist hei\\xc3\\x9f.'\n",
      "Verkrümele dich! Mach ’ne Fliege! Mir ist heiß.\n",
      "[START] verkrumele dich !  mach ne fliege !  mir ist heiss . [END]\n"
     ]
    }
   ],
   "source": [
    "example_text = tf.constant(\"Verkrümele dich! Mach ’ne Fliege! Mir ist heiß.\")\n",
    "\n",
    "print(example_text.numpy())\n",
    "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())\n",
    "\n",
    "def tf_lower_and_split_punct(text):\n",
    "    # Split accecented characters,\n",
    "    text = tf_text.normalize_utf8(text, \"NFKD\")\n",
    "    text = tf.strings.lower(text)\n",
    "    # Replace special characters.\n",
    "    text = tf.strings.regex_replace(text, 'ß', 'ss')\n",
    "    # Keep space, a to z, and select punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[^ a-z.?!,]', '')\n",
    "    # Add spaces around punctuation.\n",
    "    text = tf.strings.regex_replace(text, '[.?!,]', r' \\0 ')\n",
    "    # Strip whitespace.\n",
    "    text = tf.strings.strip(text)\n",
    "\n",
    "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "    return text\n",
    "\n",
    "print(example_text.numpy().decode())\n",
    "print(tf_lower_and_split_punct(example_text).numpy().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text vectorization.\n",
    "\n",
    "max_vocab_size = 5000\n",
    "\n",
    "input_text_processor = tf.keras.layers.TextVectorization(standardize=tf_lower_and_split_punct,\n",
    "max_tokens=max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', ',', 'ich', 'tom', '?', 'nicht']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text_processor.adapt(inp)\n",
    "\n",
    "# First 10 words from the vocabulary.\n",
    "input_text_processor.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', '[START]', '[END]', '.', 'tom', 'to', 'you', 'the', 'i']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text_processor = tf.keras.layers.TextVectorization(standardize=tf_lower_and_split_punct, max_tokens=max_vocab_size)\n",
    "\n",
    "output_text_processor.adapt(targ)\n",
    "output_text_processor.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[   2   38 1126    1  100    4    3    0    0    0    0    0    0    0\n",
      "    0    0    0    0], shape=(18,), dtype=int64)\n",
      "[START] ihr hattet [UNK] konnen . [END]           \n"
     ]
    }
   ],
   "source": [
    "# These layers can convert a batch of strings into a batch of token IDs that are zero-padded.\n",
    "example_tokens = input_text_processor(inp_batch)\n",
    "print(example_tokens[0])\n",
    "input_vocab = np.array(input_text_processor.get_vocabulary())\n",
    "tokens = input_vocab[example_tokens[0].numpy()]\n",
    "print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful class that enforces the right tensor dimensions.\n",
    "class ShapeChecker():\n",
    "    def __init__(self):\n",
    "        # Keep a cache of every axis-name seen.\n",
    "        self.shapes = {}\n",
    "\n",
    "    def __call__(self, tensor, names, broadcast=False):\n",
    "        if not tf.executing_eagerly():\n",
    "            return\n",
    "        \n",
    "        if isinstance(names, str):\n",
    "            names = (names,)\n",
    "\n",
    "        shape = tf.shape(tensor)\n",
    "        rank = tf.rank(tensor)\n",
    "\n",
    "        if rank != len(names):\n",
    "            raise ValueError(f\"Rank mismatch:\\n\"\n",
    "                             f\"     found {rank}: {shape.numpy()}\\n\"\n",
    "                             f\"     expected {len(names)}: {names}\\n\")\n",
    "\n",
    "        for i, name in enumerate(names):\n",
    "            if isinstance(name, int):\n",
    "                old_dim = name\n",
    "            else:\n",
    "                old_dim = self.shapes.get(name, None)\n",
    "            new_dim = shape[i]\n",
    "\n",
    "            if (broadcast and new_dim == 1):\n",
    "                continue\n",
    "\n",
    "            if old_dim is None:\n",
    "                # If the axis name is new, add its length to the cache.\n",
    "                self.shapes[name] = new_dim\n",
    "                continue\n",
    "\n",
    "            if new_dim != old_dim:\n",
    "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                                f\"     found: {new_dim}\\n\"\n",
    "                                f\"     expected: {old_dim}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "\n",
    "        # The embedding layer converts tokens to vectors.\n",
    "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size, embedding_dim)\n",
    "\n",
    "        # The GRU RNN layer processes those vectors sequentially.\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "        return_sequences=True,\n",
    "        return_state=True,\n",
    "        recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, tokens, state=None):\n",
    "        shape_checker = ShapeChecker() \n",
    "        shape_checker(tokens, ('batch', 's'))\n",
    "\n",
    "        # Look up the embedding for each token.\n",
    "        vectors = self.embedding(tokens)\n",
    "        shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
    "\n",
    "        # The GRU processes the embedding sequence.\n",
    "        #   ouput shape: (batch, s, enc_units)\n",
    "        #   state shape: (batch, enc_units)\n",
    "        output, state = self.gru(vectors, initial_state=state)\n",
    "        shape_checker(output, ('batch', 's', 'enc_units'))\n",
    "        shape_checker(state, ('batch', 'enc_units'))\n",
    "\n",
    "        return output, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: (batch): (64,)\n",
      "Input batch tokens shape: (batch, s): (64, 18)\n",
      "Encoder output shape: (batch, s, units): (64, 18, 1024)\n",
      "Encoder state shape: (batch, units): (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the encoder.\n",
    "\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "example_tokens = input_text_processor(inp_batch)\n",
    "\n",
    "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
    "embedding_dim, units)\n",
    "example_enc_output, example_enc_state = encoder(example_tokens)\n",
    "\n",
    "print(f'Input batch shape: (batch): {inp_batch.shape}')\n",
    "print(f'Input batch tokens shape: (batch, s): {example_tokens.shape}')\n",
    "print(f'Encoder output shape: (batch, s, units): {example_enc_output.shape}')\n",
    "print(f'Encoder state shape: (batch, units): {example_enc_state.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention layer first calculates the attention weights, \n",
    "$$\\alpha_{ts} = \\frac{\\exp(\\text{score}(\\bf{h}_t, \\bar{h}_s))}{\\sum_{s'}\\exp(\\text{score}(\\bf{h}_t, \\bar{h}_{s'}))},$$\n",
    "where the score is $\\bold{v}_a^T \\text{tanh}(\\bold{W}_1 \\bold{h}_t + \\bold{W}_2\\bold{\\bar{h}}_s)$.\n",
    "And then the context vector,\n",
    "$$\\bold{c}_t = \\sum_s \\alpha_{ts}\\bar{\\bold{h}}_s.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
    "\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\n",
    "\n",
    "    def call(self, query, value, mask):\n",
    "        \"\"\"\n",
    "        The query is generated by the decoder.\n",
    "        The value is the output of the encoder.\n",
    "        The mask is to exclude padding.\n",
    "        \"\"\"\n",
    "        shape_checker = ShapeChecker()\n",
    "        shape_checker(query, ('batch', 't', 'query_units'))\n",
    "        shape_checker(value, ('batch', 's', 'value_units'))\n",
    "        shape_checker(mask, ('batch', 's'))\n",
    "\n",
    "\n",
    "        w1_query = self.W1(query)\n",
    "        shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
    "        w2_key = self.W2(value)\n",
    "        shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
    "\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
    "        value_mask = mask\n",
    "\n",
    "        context_vector, attention_weights = self.attention(inputs = [w1_query, value, w2_key], mask=[query_mask, value_mask], return_attention_score = True)\n",
    "        shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
    "        shape_checker(attention_weights, ('batch', 't', 's'))\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 18])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test of attention layer.\n",
    "attention_layer = BahdanauAttention(units)\n",
    "(example_tokens != 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-142c56d06877>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [22]\u001b[0;36m\u001b[0m\n\u001b[0;31m    mask=(example_tokens != 0)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# The decoder will generate this.\n",
    "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
    "\n",
    "context_vector, attention_weights = attention_layer(\n",
    "    query=example_attention_query,\n",
    "    value = example_enc_output,\n",
    "    mask=(example_tokens != 0)\n",
    ")\n",
    "\n",
    "print(f\"Attention result shape: (batch_size, query_seq_length, units):  {context_vector.shape}\")\n",
    "print(f\"Attention weights shape: (batch_size, query_seq_length, value_seq_length):  {attention_weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
